\chapter{Introdução}\label{cap:introducao}

Por décadas, a Lei de Moore e a escala de Dennard impulsionaram melhorias exponenciais no desempenho computacional e na eficiência energética. A Lei de Moore permitiu aumentos constantes na densidade de transistores ao longo dos anos. Já a escala de Dennard, introduzida posteriormente, garantiu por um período que esses aumentos não viessem acompanhados de maior consumo de energia. Com o avanço tecnológico, cada uma dessas tendências atingiu seus limites, tornando os ganhos de desempenho cada vez mais difíceis, hoje limitados a somente 2\% cento ao ano~\cite{hennessy2019}. Mesmo com essas limitações, a crescente demanda por maior desempenho computacional e eficiência energética tem impulsionado inovações em uma ampla variedade de plataformas, desde sistemas embarcados até \textit{datacenters}. Essa demanda é impulsionada pela crescente complexidade das cargas de trabalho modernas, como análise de dados em tempo real, aprendizado de máquina e processamento de sinais, que exigem vastos recursos computacionais~\cite{mittal2016, dalloo2024}.

Para atender a essas demandas sob restrições de desempenho e eficiência energia, pesquisadores têm explorado paradigmas alternativos de computação. A \gls{ca} busca equilibrar precisão computacional e eficiência de recursos. CA parte do princípio de que muitas aplicações toleram resultados com imprecisão em limites aceitáveis, definidos pela percepção do usuário ou por métricas de qualidade específicas~\cite{dalloo2024}. Ao explorar a diferença entre a precisão realmente exigida e a tradicionalmente garantida pelos sistemas, a \gls{ca} viabiliza ganhos expressivos em desempenho, consumo de energia e utilização de \textit{hardware}~\cite{xu2016,leon2025a,leon2025b}.

A \gls{cp} tornou-se um paradigma central na computação moderna devido à estagnação dos ganhos de desempenho por aumento de frequência dos processadores. Para continuar evoluindo, a indústria adotou arquiteturas \textit{multicore}, nas quais múltiplas unidades de processamento trabalham simultaneamente. Nesse contexto, a \gls{cp} é empregada para acelerar aplicações dividindo seu trabalho em partes que podem ser executadas em paralelo, reduzindo significativamente o tempo total de execução. No entanto, programar para essas arquiteturas não é trivial, o desenvolvedor precisa lidar com detalhes como criação e sincronização de \textit{threads}, comunicação entre tarefas e gerenciamento de memória compartilhada. Ferramentas como o OpenMP surgiram justamente para abstrair essa complexidade, oferecendo um modelo de programação portátil baseado em diretivas que permitem paralelizar o código incrementalmente, sem comprometer a legibilidade, a manutenção ou a compatibilidade entre diferentes arquiteturas~\cite{goncalves2016, alrawais2021}. Assim, o OpenMP consolidou-se como uma das principais ferramentas de paralelização, especialmente em ambientes de Computação de Alto Desempenho (\textit{High-Performance Computing}, HPC), onde simulações científicas e aplicações numéricas dependem fortemente de execução eficiente~\cite{adhikari2012}.

Embora as técnicas de \gls{ca} ofereçam benefícios expressivos ao permitir que aplicações troquem precisão por desempenho ou eficiência energética, sua adoção eficaz exige identificar cuidadosamente as regiões de código nas quais a aproximação é segura e vantajosa. Essa análise envolve compreender o comportamento da aplicação, seus requisitos de qualidade e o impacto que imprecisões controladas podem ter em seus resultados~\cite{sampson2015, reis2021}. Este trabalho parte da hipótese de que é possível combinar \gls{cp} e \gls{ca} harmoniosamente, explorando o paralelismo de plataformas modernas enquanto se introduz flexibilidade no nível de precisão. A integração dessas abordagens, especialmente quando apoiada por ferramentas portáveis e amplamente adotadas como o OpenMP, pode ampliar os ganhos de desempenho sem sacrificar a facilidade de uso e a compatibilidade entre diferentes sistemas.

\section{Objetivos}\label{cap:objetivos}

O objetivo geral deste trabalho é melhorar o desempenho de aplicações de \gls{hpc}, por meio da combinação de técnicas de aproximação e paralelização.

Para atingir esse objetivo, foram definidos os seguintes objetivos específicos:
\begin{itemize}
    \item Implementar uma extensão do \texttt{OpenMP} com suporte a técnicas de aproximação baseadas em anotações;
    \item Desenvolver um conjunto de aplicações voltado à avaliação de técnicas de \gls{ca};
    \item Adicionar suporte em tempo de execução para múltiplos algoritmos de aproximação no \texttt{OpenMP};
    \item Integrar um passo de perforação de laços ao \textit{pipeline} de otimização do LLVM;
    \item Avaliar experimentalmente as técnicas propostas em um ambiente de \gls{ca}.
\end{itemize}

\section{Contribuições}\label{cap:contribuicoes}

As principais contribuições deste trabalho são: a implementação de uma extensão do \texttt{OpenMP} com suporte a técnicas de aproximação e a integração dessas funcionalidades à infraestrutura do LLVM. A extensão proposta exigiu modificações na infraestrutura do LLVM, bem como adaptações em algoritmos e escalonadores do \texttt{OpenMP}, a fim de possibilitar o suporte a tarefas aproximadas. Resultados parciais deste trabalho foram publicados na Escola Região de Alto Desempenho (ERAD-SP)~\cite{oliveira2024a}, Simpósio em Sistemas Computacionais de Alto Desempenho (SSCAD-2024)~\cite{oliveira2024b} e no Seminário de Iniciação Científica e Tecnológica da UTFPR (SICITE 2024)~\cite{oliveira2024c}.

\section{Organização do Trabalho}\label{cap:org_trabalho}

O restante deste trabalho está organizado da seguinte forma: no \autoref{cap:fundamentacaoTeorica} são apresentados os conceitos fundamentais de \gls{ca} e \gls{cp} relacionados a este estudo, incluindo as técnicas de aproximação abordadas, perforação de laço, memoização aproximada, descarte de tarefas e relaxamento de ponto flutuante, além de uma introdução ao \texttt{OpenMP} e uma revisão de trabalhos correlatos. No \autoref{cap:proposta} é apresentada a proposta dos construtores implementados no \texttt{OpenMP} utilizando a infraestrutura do LLVM. No \autoref{cap:metodologia} são detalhadas a metodologia, as ferramentas empregadas para a realização dos experimentos e o cronograma de execução deste trabalho.

